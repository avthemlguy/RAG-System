RAG System â€“ Document Retrieval & Semantic Search

A lightweight Retrieval-Augmented Generation (RAG) system built using:

Python

FAISS for vector search

Groq LLMs for fast embeddings & generation

Custom PDF data loader

Simple modular architecture (src/ folder)

This project loads PDF documents, converts them into vector embeddings, stores them using FAISS, and performs semantic search + summarization on top of the retrieved data.


ğŸš€ Features
âœ” PDF Ingestion

Extracts text from PDF files and splits them into chunks.

âœ” Embedding Generation (Groq)

Uses Groq models to generate dense vector embeddings.

âœ” FAISS Vector Store

Stores all embeddings locally inside faiss_store/.

âœ” Semantic Search

Retrieves the top-k most relevant chunks from your corpus.


RAG-System/
â”‚â”€â”€ main.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ pyproject.toml
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â”œâ”€â”€ search.py
â”‚   â””â”€â”€ vectorstore.py
â”‚â”€â”€ data/               # (ignored) PDF files
â”‚â”€â”€ faiss_store/        # (ignored) FAISS index + meta
â”‚â”€â”€ .env                # (ignored) environment variables


ğŸ”§ Installation

1ï¸âƒ£ Clone the repository
git clone https://github.com/avthemlguy/RAG-System.git
cd RAG-System

2ï¸âƒ£ Create a virtual environment
python3 -m venv .venv
source .venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

âœ” RAG-style Answer Generation

Combines context + query â†’ produces an answer using Groq LLM.
